{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Knowledge Distillation Training Notebook\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load the teacher model (DINOv2)\n",
        "2. Create the student model (ViT-S/16)\n",
        "3. Load and visualize the training data\n",
        "4. Train the student to mimic the teacher\n",
        "\n",
        "**No labeled data is used** - this is pure self-supervised learning!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import DataLoader\n",
        "import yaml\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "from data_loader import PretrainDataset\n",
        "from transforms import MultiCropTransform\n",
        "from optimizer import build_optimizer, build_scheduler\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load configs\n",
        "data_cfg = load_config('data_config_optimized.yaml')\n",
        "train_cfg = load_config('train_config_kd.yaml')\n",
        "model_cfg = load_config('model_config_kd.yaml')\n",
        "\n",
        "print(\"Data Config:\")\n",
        "print(f\"  Dataset: {data_cfg['dataset_name']}\")\n",
        "print(f\"  Image size: {data_cfg['image_size']}\")\n",
        "print(f\"  Workers: {data_cfg['num_workers']}\")\n",
        "\n",
        "print(\"\\nTraining Config:\")\n",
        "print(f\"  Batch size: {train_cfg['batch_size']}\")\n",
        "print(f\"  Epochs: {train_cfg['num_epochs']}\")\n",
        "print(f\"  Learning rate: {train_cfg['learning_rate']}\")\n",
        "\n",
        "print(\"\\nModel Config:\")\n",
        "print(f\"  Teacher: {model_cfg['teacher_name']}\")\n",
        "print(f\"  Student: {model_cfg['student_name']}\")\n",
        "print(f\"  Student image size: {model_cfg['student_img_size']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Teacher Model (DINOv2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading teacher model (DINOv2)...\")\n",
        "teacher_name = model_cfg['teacher_name']\n",
        "\n",
        "try:\n",
        "    teacher = torch.hub.load(\"facebookresearch/dinov2\", teacher_name)\n",
        "    teacher = teacher.to(device)\n",
        "    teacher.eval()\n",
        "    \n",
        "    # Freeze all parameters\n",
        "    for param in teacher.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_params = sum(p.numel() for p in teacher.parameters())\n",
        "    print(f\"✓ Teacher loaded: {teacher_name}\")\n",
        "    print(f\"  Parameters: {num_params / 1e6:.2f}M\")\n",
        "    print(f\"  Frozen: True\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load teacher: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Student Model (ViT-S/16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating student model...\")\n",
        "student_name = model_cfg['student_name']\n",
        "student_img_size = model_cfg['student_img_size']\n",
        "\n",
        "student = timm.create_model(\n",
        "    student_name,\n",
        "    pretrained=False,  # Random initialization\n",
        "    img_size=student_img_size,\n",
        "    num_classes=0,  # No classification head\n",
        ")\n",
        "student = student.to(device)\n",
        "student.train()\n",
        "\n",
        "num_params = sum(p.numel() for p in student.parameters())\n",
        "trainable_params = sum(p.numel() for p in student.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"✓ Student created: {student_name}\")\n",
        "print(f\"  Parameters: {num_params / 1e6:.2f}M\")\n",
        "print(f\"  Trainable: {trainable_params / 1e6:.2f}M\")\n",
        "print(f\"  Image size: {student_img_size}x{student_img_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "# Create augmentation transform\n",
        "use_multi_crop = train_cfg.get('use_multi_crop', False)\n",
        "\n",
        "if use_multi_crop:\n",
        "    transform = MultiCropTransform(\n",
        "        global_crops_scale=tuple(data_cfg.get('global_crops_scale', [0.4, 1.0])),\n",
        "        local_crops_scale=tuple(data_cfg.get('local_crops_scale', [0.05, 0.4])),\n",
        "        local_crops_number=data_cfg.get('local_crops_number', 8),\n",
        "        image_size=student_img_size\n",
        "    )\n",
        "else:\n",
        "    # Simple augmentation for KD\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(student_img_size, scale=(0.2, 1.0),\n",
        "                                   interpolation=InterpolationMode.BICUBIC),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)\n",
        "        ], p=0.8),\n",
        "        transforms.RandomGrayscale(p=0.2),\n",
        "        transforms.RandomApply([\n",
        "            transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 2.0))\n",
        "        ], p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# Create dataset\n",
        "dataset = PretrainDataset(transform=transform)\n",
        "print(f\"✓ Dataset loaded: {len(dataset)} images\")\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=data_cfg.get('num_workers', 4),\n",
        "    pin_memory=data_cfg.get('pin_memory', True),\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "print(f\"✓ DataLoader created: {len(dataloader)} batches per epoch\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a sample batch\n",
        "sample_batch = next(iter(dataloader))\n",
        "\n",
        "if isinstance(sample_batch, list):\n",
        "    # Multi-crop: show first crop\n",
        "    images = sample_batch[0]\n",
        "    print(f\"Multi-crop batch: {len(sample_batch)} crops\")\n",
        "else:\n",
        "    images = sample_batch\n",
        "    print(f\"Single-crop batch\")\n",
        "\n",
        "print(f\"Batch shape: {images.shape}\")\n",
        "\n",
        "# Visualize first 4 images\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
        "for i in range(min(4, images.shape[0])):\n",
        "    img = images[i].cpu()\n",
        "    # Denormalize\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img = img * std + mean\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    \n",
        "    axes[i].imshow(img.permute(1, 2, 0))\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f'Image {i+1}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define Feature Extraction Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_teacher_features(teacher, images, use_cls_token=True):\n",
        "    \"\"\"Extract features from frozen teacher model\"\"\"\n",
        "    with torch.no_grad():\n",
        "        features = teacher.forward_features(images)\n",
        "        \n",
        "        # Handle DINOv2 output format (dict or tensor)\n",
        "        if isinstance(features, dict):\n",
        "            if 'x_norm_clstoken' in features:\n",
        "                cls_embedding = features['x_norm_clstoken']\n",
        "            elif 'cls_token' in features:\n",
        "                cls_embedding = features['cls_token']\n",
        "            else:\n",
        "                cls_embedding = features.get('x', features.get('tokens', None))[:, 0]\n",
        "            \n",
        "            if 'x_norm_patchtokens' in features:\n",
        "                patch_embeddings = features['x_norm_patchtokens']\n",
        "            elif 'patch_tokens' in features:\n",
        "                patch_embeddings = features['patch_tokens']\n",
        "            else:\n",
        "                patch_embeddings = features.get('x', features.get('tokens', None))[:, 1:]\n",
        "        else:\n",
        "            # Tensor format [B, N+1, D]\n",
        "            if use_cls_token:\n",
        "                cls_embedding = features[:, 0]\n",
        "            else:\n",
        "                cls_embedding = features[:, 1:].mean(dim=1)\n",
        "            patch_embeddings = features[:, 1:]\n",
        "        \n",
        "        # Normalize\n",
        "        cls_embedding = F.normalize(cls_embedding, dim=-1, p=2)\n",
        "        patch_embeddings = F.normalize(patch_embeddings, dim=-1, p=2)\n",
        "    \n",
        "    return cls_embedding, patch_embeddings\n",
        "\n",
        "\n",
        "def extract_student_features(student, images, use_cls_token=True):\n",
        "    \"\"\"Extract features from student model\"\"\"\n",
        "    features = student.forward_features(images)\n",
        "    \n",
        "    if use_cls_token:\n",
        "        cls_embedding = features[:, 0]\n",
        "    else:\n",
        "        cls_embedding = features[:, 1:].mean(dim=1)\n",
        "    \n",
        "    patch_embeddings = features[:, 1:]\n",
        "    \n",
        "    # Normalize\n",
        "    cls_embedding = F.normalize(cls_embedding, dim=-1, p=2)\n",
        "    patch_embeddings = F.normalize(patch_embeddings, dim=-1, p=2)\n",
        "    \n",
        "    return cls_embedding, patch_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a small batch\n",
        "test_images = images[:2].to(device)\n",
        "\n",
        "print(\"Testing feature extraction...\")\n",
        "\n",
        "# Teacher features\n",
        "teacher_cls, teacher_patches = extract_teacher_features(teacher, test_images)\n",
        "print(f\"Teacher CLS shape: {teacher_cls.shape}\")\n",
        "print(f\"Teacher patches shape: {teacher_patches.shape}\")\n",
        "\n",
        "# Student features\n",
        "student_cls, student_patches = extract_student_features(student, test_images)\n",
        "print(f\"Student CLS shape: {student_cls.shape}\")\n",
        "print(f\"Student patches shape: {student_patches.shape}\")\n",
        "\n",
        "# Compute initial similarity\n",
        "cosine_sim_cls = F.cosine_similarity(teacher_cls, student_cls, dim=-1).mean().item()\n",
        "print(f\"\\nInitial CLS cosine similarity: {cosine_sim_cls:.4f}\")\n",
        "print(\"(This will increase during training)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Define Distillation Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_distillation_loss(student_cls, student_patches, \n",
        "                             teacher_cls, teacher_patches,\n",
        "                             loss_weights=None):\n",
        "    \"\"\"Compute distillation loss between student and teacher embeddings\"\"\"\n",
        "    if loss_weights is None:\n",
        "        loss_weights = {'cls': 1.0, 'patch': 0.5}\n",
        "    \n",
        "    # CLS token loss\n",
        "    if student_cls.shape[-1] == teacher_cls.shape[-1]:\n",
        "        loss_cls = F.mse_loss(student_cls, teacher_cls)\n",
        "    else:\n",
        "        # Different dimensions: use cosine similarity loss\n",
        "        cosine_sim = F.cosine_similarity(student_cls, teacher_cls, dim=-1)\n",
        "        loss_cls = (1 - cosine_sim).mean()\n",
        "    \n",
        "    # Patch embeddings loss\n",
        "    B_s, N_s, D_s = student_patches.shape\n",
        "    B_t, N_t, D_t = teacher_patches.shape\n",
        "    \n",
        "    if N_s == N_t and D_s == D_t:\n",
        "        loss_patch = F.mse_loss(student_patches, teacher_patches)\n",
        "    elif D_s == D_t:\n",
        "        # Same embedding dim, different num patches\n",
        "        if N_s < N_t:\n",
        "            teacher_patches = teacher_patches[:, :N_s, :]\n",
        "        else:\n",
        "            student_patches = student_patches[:, :N_t, :]\n",
        "        loss_patch = F.mse_loss(student_patches, teacher_patches)\n",
        "    else:\n",
        "        # Different dimensions: use mean-pooled cosine similarity\n",
        "        student_pooled = student_patches.mean(dim=1)\n",
        "        teacher_pooled = teacher_patches.mean(dim=1)\n",
        "        if D_s == D_t:\n",
        "            loss_patch = F.mse_loss(student_pooled, teacher_pooled)\n",
        "        else:\n",
        "            cosine_sim = F.cosine_similarity(student_pooled, teacher_pooled, dim=-1)\n",
        "            loss_patch = (1 - cosine_sim).mean()\n",
        "    \n",
        "    # Weighted combination\n",
        "    total_loss = loss_weights['cls'] * loss_cls + loss_weights['patch'] * loss_patch\n",
        "    \n",
        "    return total_loss, {\n",
        "        'total': total_loss.item(),\n",
        "        'cls': loss_cls.item(),\n",
        "        'patch': loss_patch.item()\n",
        "    }\n",
        "\n",
        "# Test loss computation\n",
        "test_loss, test_metrics = compute_distillation_loss(\n",
        "    student_cls, student_patches,\n",
        "    teacher_cls, teacher_patches,\n",
        "    loss_weights=train_cfg.get('distill_loss_weights', {'cls': 1.0, 'patch': 0.5})\n",
        ")\n",
        "print(f\"Test loss: {test_loss.item():.4f}\")\n",
        "print(f\"  CLS loss: {test_metrics['cls']:.4f}\")\n",
        "print(f\"  Patch loss: {test_metrics['patch']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Setup Optimizer and Scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build optimizer\n",
        "optimizer = build_optimizer(\n",
        "    student,\n",
        "    lr=train_cfg['learning_rate'],\n",
        "    weight_decay=train_cfg['weight_decay'],\n",
        "    fused=True\n",
        ")\n",
        "\n",
        "# Build scheduler\n",
        "scheduler = build_scheduler(\n",
        "    optimizer,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    warmup_epochs=train_cfg['warmup_epochs']\n",
        ")\n",
        "\n",
        "# GradScaler for mixed precision\n",
        "scaler = GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "print(f\"✓ Optimizer: AdamW (lr={train_cfg['learning_rate']})\")\n",
        "print(f\"✓ Scheduler: Cosine with {train_cfg['warmup_epochs']} warmup epochs\")\n",
        "print(f\"✓ Mixed precision: {'Enabled' if device.type == 'cuda' else 'Disabled'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "num_epochs = train_cfg['num_epochs']\n",
        "loss_weights = train_cfg.get('distill_loss_weights', {'cls': 1.0, 'patch': 0.5})\n",
        "use_cls_token = model_cfg.get('use_cls_token', True)\n",
        "\n",
        "# Track losses\n",
        "train_losses = []\n",
        "cls_losses = []\n",
        "patch_losses = []\n",
        "\n",
        "# Enable TF32 for faster training\n",
        "if device.type == 'cuda':\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    print(\"✓ TF32 enabled\")\n",
        "\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "print(f\"Loss weights: CLS={loss_weights['cls']}, Patch={loss_weights['patch']}\")\n",
        "print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    student.train()\n",
        "    epoch_losses = {'total': [], 'cls': [], 'patch': []}\n",
        "    \n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    \n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        # Handle multi-crop or single image\n",
        "        if isinstance(batch, list):\n",
        "            images = batch[0].to(device)  # Use first crop\n",
        "        else:\n",
        "            images = batch.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Mixed precision training\n",
        "        device_type = 'cuda' if device.type == 'cuda' else 'cpu'\n",
        "        dtype = torch.bfloat16 if device_type == 'cuda' else torch.float32\n",
        "        \n",
        "        with autocast(device_type=device_type, dtype=dtype):\n",
        "            # Teacher forward (frozen)\n",
        "            teacher_cls, teacher_patches = extract_teacher_features(\n",
        "                teacher, images, use_cls_token=use_cls_token\n",
        "            )\n",
        "            \n",
        "            # Student forward\n",
        "            student_cls, student_patches = extract_student_features(\n",
        "                student, images, use_cls_token=use_cls_token\n",
        "            )\n",
        "            \n",
        "            # Compute distillation loss\n",
        "            loss, metrics = compute_distillation_loss(\n",
        "                student_cls, student_patches,\n",
        "                teacher_cls, teacher_patches,\n",
        "                loss_weights=loss_weights\n",
        "            )\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        # Track losses\n",
        "        epoch_losses['total'].append(metrics['total'])\n",
        "        epoch_losses['cls'].append(metrics['cls'])\n",
        "        epoch_losses['patch'].append(metrics['patch'])\n",
        "        \n",
        "        # Update progress bar\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'cls': f'{metrics[\"cls\"]:.4f}',\n",
        "            'patch': f'{metrics[\"patch\"]:.4f}',\n",
        "            'lr': f'{current_lr:.6f}'\n",
        "        })\n",
        "    \n",
        "    # Step scheduler at end of epoch\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Compute epoch averages\n",
        "    avg_loss = np.mean(epoch_losses['total'])\n",
        "    avg_cls = np.mean(epoch_losses['cls'])\n",
        "    avg_patch = np.mean(epoch_losses['patch'])\n",
        "    \n",
        "    train_losses.append(avg_loss)\n",
        "    cls_losses.append(avg_cls)\n",
        "    patch_losses.append(avg_patch)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} \"\n",
        "          f\"(CLS: {avg_cls:.4f}, Patch: {avg_patch:.4f})\")\n",
        "    \n",
        "    # Save checkpoint periodically\n",
        "    checkpoint_dir = train_cfg.get('checkpoint_dir', './checkpoints')\n",
        "    checkpoint_dir = os.path.expandvars(checkpoint_dir)\n",
        "    \n",
        "    if (epoch + 1) % train_cfg.get('save_freq', 10) == 0 or (epoch + 1) == num_epochs:\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        checkpoint = {\n",
        "            'student': student.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'scaler': scaler.state_dict(),\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\")\n",
        "        print(f\"  ✓ Saved checkpoint: checkpoint_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Visualize Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Total Loss')\n",
        "plt.plot(cls_losses, label='CLS Loss', alpha=0.7)\n",
        "plt.plot(patch_losses, label='Patch Loss', alpha=0.7)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Total Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Total Loss (Log Scale)')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Best loss: {min(train_losses):.4f} (epoch {np.argmin(train_losses)+1})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Test Final Embedding Similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a batch\n",
        "student.eval()\n",
        "test_images = next(iter(dataloader))\n",
        "if isinstance(test_images, list):\n",
        "    test_images = test_images[0]\n",
        "test_images = test_images[:8].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    teacher_cls, teacher_patches = extract_teacher_features(teacher, test_images)\n",
        "    student_cls, student_patches = extract_student_features(student, test_images)\n",
        "    \n",
        "    # Compute cosine similarity\n",
        "    cosine_sim_cls = F.cosine_similarity(teacher_cls, student_cls, dim=-1).mean().item()\n",
        "    \n",
        "    # For patches, compute mean similarity\n",
        "    if student_patches.shape == teacher_patches.shape:\n",
        "        cosine_sim_patches = F.cosine_similarity(\n",
        "            student_patches.view(-1, student_patches.shape[-1]),\n",
        "            teacher_patches.view(-1, teacher_patches.shape[-1]),\n",
        "            dim=-1\n",
        "        ).mean().item()\n",
        "    else:\n",
        "        # Different shapes: use pooled embeddings\n",
        "        student_pooled = student_patches.mean(dim=1)\n",
        "        teacher_pooled = teacher_patches.mean(dim=1)\n",
        "        cosine_sim_patches = F.cosine_similarity(student_pooled, teacher_pooled, dim=-1).mean().item()\n",
        "\n",
        "print(f\"Final CLS cosine similarity: {cosine_sim_cls:.4f}\")\n",
        "print(f\"Final patch cosine similarity: {cosine_sim_patches:.4f}\")\n",
        "print(f\"\\nHigher similarity = better distillation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save Final Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final checkpoint\n",
        "checkpoint_dir = train_cfg.get('checkpoint_dir', './checkpoints')\n",
        "checkpoint_dir = os.path.expandvars(checkpoint_dir)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "final_checkpoint = {\n",
        "    'student': student.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'scheduler': scheduler.state_dict(),\n",
        "    'scaler': scaler.state_dict(),\n",
        "    'epoch': num_epochs - 1,\n",
        "    'train_losses': train_losses,\n",
        "    'config': {\n",
        "        'model': model_cfg,\n",
        "        'train': train_cfg,\n",
        "        'data': data_cfg\n",
        "    }\n",
        "}\n",
        "\n",
        "torch.save(final_checkpoint, f\"{checkpoint_dir}/checkpoint_final.pth\")\n",
        "print(f\"✓ Final model saved to: {checkpoint_dir}/checkpoint_final.pth\")\n",
        "print(f\"\\nYou can now use this checkpoint for feature extraction and evaluation!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
