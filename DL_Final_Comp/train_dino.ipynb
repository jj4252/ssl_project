{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DINO Pretraining Notebook\n",
        "\n",
        "This notebook runs the full DINO self-supervised pretraining on unlabeled images.\n",
        "\n",
        "**Note**: Evaluation datasets are not yet available, so this focuses on pretraining only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import yaml\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Import our modules\n",
        "from data_loader import PretrainDataset\n",
        "from transforms import MultiCropTransform\n",
        "from vit_model import build_vit\n",
        "from dino_wrapper import DINO\n",
        "from optimizer import build_optimizer, build_scheduler, cosine_schedule\n",
        "from train_dino import train_dino, train_epoch, dino_loss\n",
        "\n",
        "print(\"âœ“ All imports successful\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load configs\n",
        "# OPTIMIZED: Use optimized configs for ~5-8x speedup (recommended)\n",
        "# DEFAULT: Use original configs for baseline comparison\n",
        "config_mode = \"optimized\"  # Options: \"optimized\", \"default\"\n",
        "\n",
        "if config_mode == \"optimized\":\n",
        "    data_cfg = load_config('data_config_optimized.yaml')\n",
        "    train_cfg = load_config('train_config_optimized.yaml')\n",
        "    print(\"âš¡ Using OPTIMIZED configs (~5-8x speedup)\")\n",
        "    print(\"  - 2 global + 2 local crops (4 total)\")\n",
        "    print(\"  - 75 epochs, 5 warmup\")\n",
        "    print(\"  - Reduced projection head (32k)\")\n",
        "    print(\"  - All performance optimizations enabled\")\n",
        "else:\n",
        "    data_cfg = load_config('data_config.yaml')\n",
        "    train_cfg = load_config('train_config.yaml')\n",
        "    print(\"ðŸ“Š Using DEFAULT configs (baseline)\")\n",
        "\n",
        "model_cfg = load_config('model_config.yaml')\n",
        "\n",
        "print(\"=== Configuration ===\")\n",
        "print(f\"Model: {model_cfg['model_name']}\")\n",
        "print(f\"Image size: {data_cfg['image_size']}\")\n",
        "print(f\"Batch size: {train_cfg['batch_size']}\")\n",
        "print(f\"Epochs: {train_cfg['num_epochs']}\")\n",
        "print(f\"Learning rate: {train_cfg['learning_rate']}\")\n",
        "print(f\"Local crops: {data_cfg['local_crops_number']}\")\n",
        "print(f\"Total crops per image: {2 + data_cfg['local_crops_number']} (2 global + {data_cfg['local_crops_number']} local)\")\n",
        "print(f\"Data workers: {data_cfg.get('num_workers', 4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Setup Device and Checkpoint Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create checkpoint directory\n",
        "checkpoint_dir = train_cfg.get('checkpoint_dir', './checkpoints')\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(f\"Checkpoints will be saved to: {checkpoint_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Pretraining Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create multi-crop transform\n",
        "transform = MultiCropTransform(\n",
        "    global_crops_scale=tuple(data_cfg['global_crops_scale']),\n",
        "    local_crops_scale=tuple(data_cfg['local_crops_scale']),\n",
        "    local_crops_number=data_cfg['local_crops_number'],\n",
        "    image_size=data_cfg['image_size']\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading pretraining dataset...\")\n",
        "pretrain_dataset = PretrainDataset(transform=transform)\n",
        "print(f\"Dataset size: {len(pretrain_dataset)}\")\n",
        "\n",
        "# Create DataLoader with optimizations\n",
        "train_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=data_cfg['num_workers'],\n",
        "    pin_memory=data_cfg['pin_memory'],\n",
        "    drop_last=True,\n",
        "    persistent_workers=data_cfg.get('persistent_workers', False),  # Keep workers alive between epochs\n",
        "    prefetch_factor=data_cfg.get('prefetch_factor', 2)  # Prefetch batches\n",
        ")\n",
        "\n",
        "print(f\"Number of batches per epoch: {len(train_loader)}\")\n",
        "print(f\"Total training steps: {len(train_loader) * train_cfg['num_epochs']}\")\n",
        "print(f\"Effective batch size: {train_cfg['batch_size']} Ã— {2 + data_cfg['local_crops_number']} crops = {train_cfg['batch_size'] * (2 + data_cfg['local_crops_number'])} forward passes per batch\")\n",
        "print(f\"Data workers: {data_cfg['num_workers']} (with persistent_workers={data_cfg.get('persistent_workers', False)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build ViT backbone\n",
        "print(f\"Building {model_cfg['model_name']}...\")\n",
        "backbone = build_vit(\n",
        "    model_name=model_cfg['model_name'],\n",
        "    img_size=model_cfg['img_size'],\n",
        "    patch_size=model_cfg['patch_size'],\n",
        "    drop_path_rate=model_cfg['drop_path_rate']\n",
        ")\n",
        "\n",
        "# Build DINO model\n",
        "model = DINO(\n",
        "    backbone,\n",
        "    out_dim=train_cfg['out_dim'],\n",
        "    use_cls_token=model_cfg['use_cls_token']\n",
        ")\n",
        "\n",
        "# Move to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel created successfully!\")\n",
        "print(f\"Total parameters: {total_params / 1e6:.2f}M\")\n",
        "print(f\"Trainable parameters: {trainable_params / 1e6:.2f}M\")\n",
        "print(f\"Model size: {total_params * 4 / 1e6:.2f} MB (float32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup Optimizer and Scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable performance optimizations\n",
        "if device.type == 'cuda':\n",
        "    torch.backends.cuda.matmul.allow_tf32 = train_cfg.get('use_tf32', True)\n",
        "    torch.backends.cudnn.allow_tf32 = train_cfg.get('use_tf32', True)\n",
        "    if train_cfg.get('use_tf32', True):\n",
        "        print(\"âœ“ TF32 enabled for faster training\")\n",
        "\n",
        "# Convert model to channels_last if enabled\n",
        "if train_cfg.get('use_channels_last', False) and device.type == 'cuda':\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    print(\"âœ“ Model converted to channels_last format\")\n",
        "\n",
        "# Create optimizer with fused AdamW if enabled\n",
        "optimizer = build_optimizer(\n",
        "    model,\n",
        "    lr=train_cfg['learning_rate'],\n",
        "    weight_decay=train_cfg['weight_decay'],\n",
        "    fused=train_cfg.get('use_fused_adamw', True)\n",
        ")\n",
        "\n",
        "# Create scheduler\n",
        "scheduler = build_scheduler(\n",
        "    optimizer,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    warmup_epochs=train_cfg['warmup_epochs']\n",
        ")\n",
        "\n",
        "# Create gradient scaler for mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "# Initialize center for DINO\n",
        "out_dim = train_cfg['out_dim']\n",
        "center = torch.zeros(out_dim, device=device)\n",
        "\n",
        "# Compile model if enabled (AFTER creating optimizer, BEFORE training)\n",
        "# Note: Compile after checkpoint loading if resuming\n",
        "use_compile = train_cfg.get('use_torch_compile', False)\n",
        "compiled_model = None\n",
        "if use_compile and hasattr(torch, 'compile'):\n",
        "    print(\"Note: Model will be compiled after checkpoint loading (if resuming)\")\n",
        "\n",
        "print(\"\\nOptimizer and scheduler created\")\n",
        "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")\n",
        "print(f\"Warmup epochs: {train_cfg['warmup_epochs']}\")\n",
        "print(f\"Total epochs: {train_cfg['num_epochs']}\")\n",
        "print(f\"Projection head size: {out_dim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training history\n",
        "train_losses = []\n",
        "learning_rates = []\n",
        "\n",
        "# Resume from checkpoint if specified\n",
        "start_epoch = 0\n",
        "resume_from = None  # Set to checkpoint path if resuming, e.g., \"checkpoints/checkpoint_epoch_50.pth\"\n",
        "\n",
        "if resume_from and os.path.exists(resume_from):\n",
        "    print(f\"Loading checkpoint from {resume_from}...\")\n",
        "    checkpoint = torch.load(resume_from, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    scaler.load_state_dict(checkpoint['scaler'])\n",
        "    center = checkpoint['center']\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"Resumed from epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"Starting training from scratch\")\n",
        "\n",
        "# Compile model now (after checkpoint loading if resuming)\n",
        "if use_compile and hasattr(torch, 'compile') and compiled_model is None:\n",
        "    print(\"Compiling model with torch.compile...\")\n",
        "    model = torch.compile(model, mode='reduce-overhead')\n",
        "    print(\"âœ“ Model compiled\")\n",
        "\n",
        "# Performance optimizations summary:\n",
        "# âœ“ Reduced crops: 2 global + 2 local (4 total vs 10)\n",
        "# âœ“ Restricted loss pairings (avoid local-to-local)\n",
        "# âœ“ Reduced projection head (32k vs 65k)\n",
        "# âœ“ Shorter training (75 epochs vs 200)\n",
        "# âœ“ torch.compile, channels_last, BF16, TF32, fused AdamW\n",
        "# âœ“ Optimized data loading (24 workers, persistent, prefetch)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Starting training for {train_cfg['num_epochs']} epochs\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main training loop\n",
        "for epoch in range(start_epoch, train_cfg['num_epochs']):\n",
        "    epoch_start_time = datetime.now()\n",
        "    \n",
        "    # Train one epoch with optimized settings\n",
        "    num_global = 2\n",
        "    num_local = data_cfg['local_crops_number']\n",
        "    \n",
        "    avg_loss, center = train_epoch(\n",
        "        model=model,\n",
        "        dataloader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        center=center,\n",
        "        device=device,\n",
        "        scaler=scaler,\n",
        "        epoch=epoch,\n",
        "        num_epochs=train_cfg['num_epochs'],\n",
        "        teacher_temp=train_cfg['teacher_temp'],\n",
        "        student_temp=train_cfg['student_temp'],\n",
        "        warmup_teacher_temp=train_cfg['warmup_teacher_temp'],\n",
        "        warmup_teacher_temp_epochs=train_cfg['warmup_teacher_temp_epochs'],\n",
        "        num_global=num_global,\n",
        "        num_local=num_local\n",
        "    )\n",
        "    \n",
        "    # Record history\n",
        "    train_losses.append(avg_loss)\n",
        "    learning_rates.append(scheduler.get_last_lr()[0])\n",
        "    \n",
        "    # Calculate epoch time\n",
        "    epoch_time = (datetime.now() - epoch_start_time).total_seconds()\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f\"\\nEpoch {epoch+1}/{train_cfg['num_epochs']} Summary:\")\n",
        "    print(f\"  Loss: {avg_loss:.4f}\")\n",
        "    print(f\"  Learning rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "    print(f\"  Time: {epoch_time:.1f}s ({epoch_time/60:.1f} min)\")\n",
        "    \n",
        "    # Save checkpoint\n",
        "    checkpoint = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'scaler': scaler.state_dict(),\n",
        "        'center': center,\n",
        "        'epoch': epoch,\n",
        "        'config': {\n",
        "            'model': model_cfg,\n",
        "            'train': train_cfg,\n",
        "            'data': data_cfg\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Save latest\n",
        "    torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_latest.pth\")\n",
        "    \n",
        "    # Save periodic checkpoints\n",
        "    if (epoch + 1) % train_cfg.get('save_freq', 10) == 0 or (epoch + 1) == train_cfg['num_epochs']:\n",
        "        torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\")\n",
        "        print(f\"  Checkpoint saved: checkpoint_epoch_{epoch+1}.pth\")\n",
        "    \n",
        "    # Estimate remaining time\n",
        "    if epoch > start_epoch:\n",
        "        avg_time_per_epoch = sum([(datetime.now() - epoch_start_time).total_seconds()]) / (epoch - start_epoch + 1)\n",
        "        remaining_epochs = train_cfg['num_epochs'] - epoch - 1\n",
        "        remaining_time = avg_time_per_epoch * remaining_epochs\n",
        "        print(f\"  Estimated time remaining: {remaining_time/3600:.1f} hours\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training completed!\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Plot Training Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(learning_rates)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate Schedule')\n",
        "plt.grid(True)\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{checkpoint_dir}/training_curves.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Training curves saved to {checkpoint_dir}/training_curves.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Final Model Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Training Summary ===\")\n",
        "print(f\"Total epochs: {len(train_losses)}\")\n",
        "print(f\"Final loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Best loss: {min(train_losses):.4f} (epoch {train_losses.index(min(train_losses))+1})\")\n",
        "print(f\"\\nCheckpoints saved in: {checkpoint_dir}\")\n",
        "print(f\"Latest checkpoint: {checkpoint_dir}/checkpoint_latest.pth\")\n",
        "print(f\"Final checkpoint: {checkpoint_dir}/checkpoint_epoch_{len(train_losses)}.pth\")\n",
        "\n",
        "# Show checkpoint files\n",
        "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "print(f\"\\nAll checkpoints ({len(checkpoint_files)}):\")\n",
        "for f in sorted(checkpoint_files):\n",
        "    size = os.path.getsize(f\"{checkpoint_dir}/{f}\") / 1e6\n",
        "    print(f\"  - {f} ({size:.1f} MB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Next Steps\n",
        "\n",
        "Once evaluation datasets become available, you can:\n",
        "\n",
        "1. **Extract features** using `extract_features_main.py`:\n",
        "   ```python\n",
        "   !python extract_features_main.py \\\n",
        "       --checkpoint checkpoints/checkpoint_latest.pth \\\n",
        "       --data_config data_config.yaml \\\n",
        "       --model_config model_config.yaml \\\n",
        "       --eval_config eval_config.yaml \\\n",
        "       --output_dir ./features \\\n",
        "       --device cuda\n",
        "   ```\n",
        "\n",
        "2. **Evaluate with k-NN** using `knn_eval_main.py`:\n",
        "   ```python\n",
        "   !python knn_eval_main.py \\\n",
        "       --features features/features.pt \\\n",
        "       --eval_config eval_config.yaml\n",
        "   ```\n",
        "\n",
        "3. **Optional: Linear probe** by setting `linear_probe: true` in `eval_config.yaml`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
