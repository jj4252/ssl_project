{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DINO Pipeline Testing Notebook\n",
        "\n",
        "This notebook tests each step of the DINO self-supervised learning pipeline to verify everything works correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import yaml\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import our modules\n",
        "from data_loader import PretrainDataset, EvalDataset\n",
        "from transforms import MultiCropTransform, EvalTransform\n",
        "from vit_model import build_vit\n",
        "from dino_wrapper import DINO, DINOHead\n",
        "from optimizer import build_optimizer, build_scheduler, cosine_schedule\n",
        "from train_dino import dino_loss, train_epoch\n",
        "from extract_features import extract_features\n",
        "from knn_eval import knn_evaluate, knn_evaluate_multiple_k\n",
        "\n",
        "print(\"✓ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load configs\n",
        "data_cfg = load_config('data_config.yaml')\n",
        "model_cfg = load_config('model_config.yaml')\n",
        "train_cfg = load_config('train_config.yaml')\n",
        "eval_cfg = load_config('eval_config.yaml')\n",
        "\n",
        "print(\"Data Config:\", data_cfg)\n",
        "print(\"\\nModel Config:\", model_cfg)\n",
        "print(\"\\nTrain Config:\", train_cfg)\n",
        "print(\"\\nEval Config:\", eval_cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test pretraining dataset\n",
        "print(\"=== Testing Pretraining Dataset ===\")\n",
        "transform = MultiCropTransform(\n",
        "    global_crops_scale=tuple(data_cfg['global_crops_scale']),\n",
        "    local_crops_scale=tuple(data_cfg['local_crops_scale']),\n",
        "    local_crops_number=data_cfg['local_crops_number'],\n",
        "    image_size=data_cfg['image_size']\n",
        ")\n",
        "\n",
        "print(\"Creating pretraining dataset...\")\n",
        "pretrain_dataset = PretrainDataset(transform=transform)\n",
        "print(f\"Dataset size: {len(pretrain_dataset)}\")\n",
        "\n",
        "# Get one sample\n",
        "sample = pretrain_dataset[0]\n",
        "print(f\"\\nNumber of crops: {len(sample)}\")\n",
        "print(f\"Crop shapes: {[c.shape for c in sample]}\")\n",
        "print(f\"Crop dtypes: {[c.dtype for c in sample]}\")\n",
        "print(f\"Crop value ranges: {[(c.min().item(), c.max().item()) for c in sample]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test evaluation dataset\n",
        "print(\"=== Testing Evaluation Dataset ===\")\n",
        "eval_transform = EvalTransform(image_size=data_cfg['image_size'])\n",
        "\n",
        "print(\"Creating evaluation train dataset...\")\n",
        "eval_train_dataset = EvalDataset(split='train', transform=eval_transform)\n",
        "print(f\"Train dataset size: {len(eval_train_dataset)}\")\n",
        "\n",
        "print(\"\\nCreating evaluation test dataset...\")\n",
        "eval_test_dataset = EvalDataset(split='test', transform=eval_transform)\n",
        "print(f\"Test dataset size: {len(eval_test_dataset)}\")\n",
        "\n",
        "# Get one sample\n",
        "image, label = eval_train_dataset[0]\n",
        "print(f\"\\nImage shape: {image.shape}\")\n",
        "print(f\"Label: {label}\")\n",
        "print(f\"Image dtype: {image.dtype}\")\n",
        "print(f\"Image value range: ({image.min().item():.3f}, {image.max().item():.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test DataLoader\n",
        "print(\"=== Testing DataLoader ===\")\n",
        "pretrain_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=4,  # Small batch for testing\n",
        "    shuffle=True,\n",
        "    num_workers=0,  # Set to 0 for debugging\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "batch = next(iter(pretrain_loader))\n",
        "print(f\"Batch type: {type(batch)}\")\n",
        "print(f\"Number of crops in batch: {len(batch)}\")\n",
        "print(f\"Batch shapes: {[c.shape for c in batch]}\")\n",
        "print(f\"\\nFirst crop shape: {batch[0].shape}\")\n",
        "print(f\"Second crop shape: {batch[1].shape}\")\n",
        "print(f\"First local crop shape: {batch[2].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Model Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing Model Creation ===\")\n",
        "\n",
        "# Build backbone\n",
        "print(f\"Building {model_cfg['model_name']}...\")\n",
        "backbone = build_vit(\n",
        "    model_name=model_cfg['model_name'],\n",
        "    img_size=model_cfg['img_size'],\n",
        "    patch_size=model_cfg['patch_size'],\n",
        "    drop_path_rate=model_cfg['drop_path_rate']\n",
        ")\n",
        "\n",
        "print(f\"Backbone embed_dim: {backbone.embed_dim}\")\n",
        "print(f\"Backbone parameters: {sum(p.numel() for p in backbone.parameters()) / 1e6:.2f}M\")\n",
        "\n",
        "# Test forward pass\n",
        "dummy_input = torch.randn(2, 3, 96, 96)\n",
        "with torch.no_grad():\n",
        "    features = backbone.forward_features(dummy_input)\n",
        "    print(f\"\\nInput shape: {dummy_input.shape}\")\n",
        "    print(f\"Features shape: {features.shape}\")\n",
        "    print(f\"CLS token shape: {features[:, 0].shape}\")\n",
        "    print(f\"Patch tokens shape: {features[:, 1:].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build DINO model\n",
        "print(\"=== Testing DINO Model ===\")\n",
        "model = DINO(\n",
        "    backbone,\n",
        "    out_dim=train_cfg['out_dim'],\n",
        "    use_cls_token=model_cfg['use_cls_token']\n",
        ")\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params / 1e6:.2f}M\")\n",
        "print(f\"Trainable parameters: {trainable_params / 1e6:.2f}M\")\n",
        "print(f\"Student head parameters: {sum(p.numel() for p in model.student_head.parameters()) / 1e6:.2f}M\")\n",
        "\n",
        "# Test forward pass with multi-crop\n",
        "dummy_crops = [torch.randn(2, 3, 96, 96) for _ in range(4)]  # 2 global + 2 local\n",
        "print(f\"\\nTesting forward pass with {len(dummy_crops)} crops...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    student_outputs = model(dummy_crops, is_teacher=False)\n",
        "    teacher_outputs = model(dummy_crops, is_teacher=True)\n",
        "\n",
        "print(f\"Number of student outputs: {len(student_outputs)}\")\n",
        "print(f\"Student output shape: {student_outputs[0].shape}\")\n",
        "print(f\"Teacher output shape: {teacher_outputs[0].shape}\")\n",
        "print(f\"Output dimension: {student_outputs[0].shape[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing DINO Loss ===\")\n",
        "\n",
        "# Create dummy outputs\n",
        "batch_size = 4\n",
        "out_dim = train_cfg['out_dim']\n",
        "num_crops = 4\n",
        "\n",
        "student_outputs = [torch.randn(batch_size, out_dim) for _ in range(num_crops)]\n",
        "teacher_outputs = [torch.randn(batch_size, out_dim) for _ in range(num_crops)]\n",
        "center = torch.zeros(out_dim)\n",
        "\n",
        "loss = dino_loss(\n",
        "    student_outputs,\n",
        "    teacher_outputs,\n",
        "    center,\n",
        "    teacher_temp=train_cfg['teacher_temp'],\n",
        "    student_temp=train_cfg['student_temp']\n",
        ")\n",
        "\n",
        "print(f\"Loss value: {loss.item():.4f}\")\n",
        "print(f\"Loss shape: {loss.shape}\")\n",
        "print(f\"Loss requires grad: {loss.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Optimizer and Scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing Optimizer and Scheduler ===\")\n",
        "\n",
        "optimizer = build_optimizer(\n",
        "    model,\n",
        "    lr=train_cfg['learning_rate'],\n",
        "    weight_decay=train_cfg['weight_decay']\n",
        ")\n",
        "\n",
        "scheduler = build_scheduler(\n",
        "    optimizer,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    warmup_epochs=train_cfg['warmup_epochs']\n",
        ")\n",
        "\n",
        "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
        "print(f\"Number of parameter groups: {len(optimizer.param_groups)}\")\n",
        "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "# Test scheduler for a few steps\n",
        "print(\"\\nTesting scheduler (first 5 steps):\")\n",
        "for i in range(5):\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Step {i}: LR = {lr:.6f}\")\n",
        "    scheduler.step()\n",
        "\n",
        "# Test momentum schedule\n",
        "print(\"\\nTesting momentum schedule:\")\n",
        "for epoch in [0, 10, 50, 100, 199]:\n",
        "    momentum = cosine_schedule(epoch, max_epochs=200, base_value=0.996, final_value=1.0)\n",
        "    print(f\"Epoch {epoch}: Momentum = {momentum:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Training Step (Single Batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing Single Training Step ===\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Create a small dataloader\n",
        "small_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# Get one batch\n",
        "crops = next(iter(small_loader))\n",
        "crops = [c.to(device) for c in crops]\n",
        "\n",
        "print(f\"Batch crops: {len(crops)}\")\n",
        "print(f\"Crop shapes: {[c.shape for c in crops]}\")\n",
        "\n",
        "# Initialize optimizer and scaler\n",
        "optimizer = build_optimizer(model, lr=train_cfg['learning_rate'], weight_decay=train_cfg['weight_decay'])\n",
        "scheduler = build_scheduler(optimizer, num_epochs=train_cfg['num_epochs'], warmup_epochs=train_cfg['warmup_epochs'])\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "out_dim = train_cfg['out_dim']\n",
        "center = torch.zeros(out_dim, device=device)\n",
        "\n",
        "# Forward pass\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "    student_outputs = model(crops, is_teacher=False)\n",
        "    with torch.no_grad():\n",
        "        teacher_outputs = model(crops, is_teacher=True)\n",
        "    \n",
        "    loss = dino_loss(\n",
        "        student_outputs, teacher_outputs, center,\n",
        "        teacher_temp=train_cfg['teacher_temp'],\n",
        "        student_temp=train_cfg['student_temp']\n",
        "    )\n",
        "\n",
        "print(f\"\\nLoss: {loss.item():.4f}\")\n",
        "\n",
        "# Backward pass\n",
        "scaler.scale(loss).backward()\n",
        "scaler.step(optimizer)\n",
        "scaler.update()\n",
        "scheduler.step()\n",
        "\n",
        "print(f\"Learning rate after step: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "# Update teacher\n",
        "momentum = cosine_schedule(0, max_epochs=200, base_value=0.996, final_value=1.0)\n",
        "model.update_teacher(momentum)\n",
        "print(f\"Teacher updated with momentum: {momentum:.6f}\")\n",
        "\n",
        "# Update center\n",
        "with torch.no_grad():\n",
        "    teacher_out = torch.stack(teacher_outputs)\n",
        "    center = 0.9 * center + 0.1 * teacher_out.mean(dim=0).mean(dim=0)\n",
        "print(f\"Center updated, mean: {center.mean().item():.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing Feature Extraction ===\")\n",
        "\n",
        "# Create a small evaluation dataset\n",
        "eval_transform = EvalTransform(image_size=data_cfg['image_size'])\n",
        "eval_dataset = EvalDataset(split='train', transform=eval_transform)\n",
        "\n",
        "eval_loader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# Extract features from a few batches\n",
        "model.eval()\n",
        "backbone = model.get_backbone()\n",
        "backbone.eval()\n",
        "\n",
        "print(\"\\nExtracting features from first 2 batches...\")\n",
        "features_list = []\n",
        "labels_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(eval_loader):\n",
        "        if i >= 2:\n",
        "            break\n",
        "        \n",
        "        images = images.to(device)\n",
        "        outputs = backbone.forward_features(images)\n",
        "        \n",
        "        if model_cfg['use_cls_token']:\n",
        "            feat = outputs[:, 0]  # CLS token\n",
        "        else:\n",
        "            feat = outputs[:, 1:].mean(dim=1)  # Mean-pool\n",
        "        \n",
        "        feat = nn.functional.normalize(feat, dim=-1, p=2)\n",
        "        \n",
        "        features_list.append(feat.cpu())\n",
        "        labels_list.append(labels)\n",
        "        \n",
        "        print(f\"Batch {i+1}: features shape = {feat.shape}, labels shape = {labels.shape}\")\n",
        "\n",
        "features = torch.cat(features_list, dim=0)\n",
        "labels = torch.cat(labels_list, dim=0)\n",
        "\n",
        "print(f\"\\nTotal features shape: {features.shape}\")\n",
        "print(f\"Total labels shape: {labels.shape}\")\n",
        "print(f\"Feature norm (should be ~1.0): {features.norm(dim=1).mean().item():.4f}\")\n",
        "print(f\"Unique labels: {torch.unique(labels).tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test k-NN Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Testing k-NN Evaluation ===\")\n",
        "\n",
        "# Create dummy train and test features\n",
        "train_features = torch.randn(100, backbone.embed_dim)\n",
        "train_features = nn.functional.normalize(train_features, dim=-1, p=2)\n",
        "train_labels = torch.randint(0, 10, (100,))\n",
        "\n",
        "test_features = torch.randn(20, backbone.embed_dim)\n",
        "test_features = nn.functional.normalize(test_features, dim=-1, p=2)\n",
        "test_labels = torch.randint(0, 10, (20,))\n",
        "\n",
        "print(f\"Train features: {train_features.shape}\")\n",
        "print(f\"Train labels: {train_labels.shape}\")\n",
        "print(f\"Test features: {test_features.shape}\")\n",
        "print(f\"Test labels: {test_labels.shape}\")\n",
        "\n",
        "# Test k-NN with different k values\n",
        "k_values = [5, 10, 20]\n",
        "results = knn_evaluate_multiple_k(\n",
        "    train_features, train_labels,\n",
        "    test_features, test_labels,\n",
        "    k_values=k_values\n",
        ")\n",
        "\n",
        "print(f\"\\nResults: {results}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Pipeline Summary ===\")\n",
        "print(\"\\n✓ Data loading works\")\n",
        "print(\"✓ Model creation works\")\n",
        "print(\"✓ Loss computation works\")\n",
        "print(\"✓ Optimizer and scheduler work\")\n",
        "print(\"✓ Training step works\")\n",
        "print(\"✓ Feature extraction works\")\n",
        "print(\"✓ k-NN evaluation works\")\n",
        "print(\"\\nAll components are ready for full training!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
