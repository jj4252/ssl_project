{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Knowledge Distillation Training with Cached Tensors (2-Stage Pipeline)\n",
        "\n",
        "This notebook demonstrates the **2-stage cached training pipeline**:\n",
        "1. **Stage 1**: Precompute and cache preprocessed image tensors\n",
        "2. **Stage 2**: Train using cached tensors for fast data loading\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- ✅ **2-Stage Pipeline**: Precompute once, train many times\n",
        "- ✅ **Cached Tensors**: 10-20× faster data loading (no HuggingFace API calls)\n",
        "- ✅ **Step-capped epochs**: Only `max_steps_per_epoch` batches per epoch\n",
        "- ✅ **Auto-resume**: Automatically detects and resumes from latest checkpoint\n",
        "- ✅ **Optimized DataLoader**: Fast tensor loading from shard files\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. **Precompute cache** (one-time, ~2-4 hours): Process all 500K images and save as tensor shards\n",
        "2. **Train with cache** (fast): Load from cached tensors instead of HuggingFace\n",
        "\n",
        "**No labeled data is used** - this is pure self-supervised learning!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler\n",
        "# Try to import new autocast API (PyTorch 2.0+), fall back to old API\n",
        "try:\n",
        "    from torch.amp import autocast  # PyTorch 2.0+\n",
        "    AUTOCAST_NEW_API = True\n",
        "except ImportError:\n",
        "    from torch.cuda.amp import autocast  # PyTorch < 2.0\n",
        "    AUTOCAST_NEW_API = False\n",
        "from torch.utils.data import DataLoader\n",
        "import yaml\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "import itertools  # For limiting DataLoader iterations\n",
        "import hashlib  # For teacher feature caching\n",
        "from pathlib import Path  # For teacher feature caching\n",
        "\n",
        "from data_loader import build_pretraining_dataloader, build_precompute_dataset, CachedTensorDataset\n",
        "from transforms import SimpleTransform, FastMultiCropTransform\n",
        "from optimizer import build_optimizer, build_scheduler\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    # Enable TF32 for faster training\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    print(\"✓ TF32 enabled for faster training\")\n",
        "else:\n",
        "    print(\"⚠️  WARNING: Running on CPU - training will be very slow!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load configs\n",
        "data_cfg = load_config('data_config.yaml')\n",
        "train_cfg = load_config('train_config_kd.yaml')\n",
        "model_cfg = load_config('model_config_kd.yaml')\n",
        "\n",
        "print(\"Data Config:\")\n",
        "print(f\"  Dataset: {data_cfg['dataset_name']}\")\n",
        "print(f\"  Image size: {data_cfg['image_size']}\")\n",
        "print(f\"  Workers: {data_cfg['num_workers']}\")\n",
        "print(f\"  Use cached: {data_cfg.get('use_cached', False)}\")\n",
        "if data_cfg.get('use_cached', False):\n",
        "    print(f\"  Cache dir: {data_cfg.get('cache_dir', 'N/A')}\")\n",
        "    print(f\"  Shard size: {data_cfg.get('cache_shard_size', 'N/A')}\")\n",
        "\n",
        "print(\"\\nTraining Config:\")\n",
        "print(f\"  Batch size: {train_cfg['batch_size']}\")\n",
        "print(f\"  Epochs: {train_cfg['num_epochs']}\")\n",
        "print(f\"  Learning rate: {train_cfg['learning_rate']}\")\n",
        "print(f\"  Max steps per epoch: {train_cfg.get('max_steps_per_epoch', 'None (full epoch)')}\")\n",
        "\n",
        "print(\"\\nModel Config:\")\n",
        "print(f\"  Teacher: {model_cfg['teacher_name']}\")\n",
        "print(f\"  Student: {model_cfg['student_name']}\")\n",
        "print(f\"  Student image size: {model_cfg['student_img_size']}\")\n",
        "\n",
        "# Get settings\n",
        "use_cached = data_cfg.get('use_cached', False)\n",
        "max_steps_per_epoch = train_cfg.get('max_steps_per_epoch', None)\n",
        "\n",
        "if use_cached:\n",
        "    cache_dir = data_cfg.get('cache_dir', './cache_images')\n",
        "    cache_dir = os.path.expandvars(cache_dir)\n",
        "    print(f\"\\n✓ Cached mode enabled\")\n",
        "    print(f\"  Cache directory: {cache_dir}\")\n",
        "    # Check if cache exists\n",
        "    index_path = os.path.join(cache_dir, 'index.json')\n",
        "    if os.path.exists(index_path):\n",
        "        print(f\"  ✓ Cache found: {index_path}\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  Cache not found! Run Stage 1 (precompute) first.\")\n",
        "else:\n",
        "    print(f\"\\n✓ Original mode (HuggingFace/raw images)\")\n",
        "    print(f\"  To use cached mode, set use_cached: true in data_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stage 1: Precompute Cache (One-Time Setup)\n",
        "\n",
        "**Run this section once** to preprocess and cache all images. This takes ~2-4 hours but only needs to be done once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stage 1: Precompute cache\n",
        "# Uncomment and run this cell to create the cache (one-time, ~2-4 hours)\n",
        "\n",
        "# from precompute_cache import precompute_cache\n",
        "# \n",
        "# print(\"Starting cache precomputation...\")\n",
        "# print(\"This will process all 500K images and save as tensor shards.\")\n",
        "# print(\"Expected time: ~2-4 hours\")\n",
        "# print(\"-\" * 60)\n",
        "# \n",
        "# precompute_cache(data_cfg, train_cfg, batch_size=256)\n",
        "# \n",
        "# print(\"\\n✓ Cache precomputation complete!\")\n",
        "# print(\"  You can now set use_cached: true in data_config.yaml and proceed to training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stage 2: Training with Cached Data\n",
        "\n",
        "This section loads models and trains using cached tensors (if `use_cached: true`) or original dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Teacher Model (DINOv2) - NOT Compiled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "print(\"Loading teacher model (DINOv2)...\")\n",
        "print(\"⚠️  Teacher will NOT be compiled (frozen, no benefit)\")\n",
        "teacher_name = model_cfg['teacher_name']\n",
        "\n",
        "# For Python < 3.10, use patcher for compatibility\n",
        "if sys.version_info < (3, 10):\n",
        "    try:\n",
        "        from dinov2_patcher import load_dinov2_with_patch\n",
        "        print(\"Using Python 3.9 compatibility patcher...\")\n",
        "        teacher = load_dinov2_with_patch(teacher_name, verbose=False)\n",
        "    except ImportError:\n",
        "        print(\"⚠️  Warning: dinov2_patcher not available. Trying direct load...\")\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*xFormers.*\")\n",
        "            teacher = torch.hub.load(\"facebookresearch/dinov2\", teacher_name, verbose=False)\n",
        "else:\n",
        "    # Python 3.10+: direct load\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*xFormers.*\")\n",
        "        teacher = torch.hub.load(\"facebookresearch/dinov2\", teacher_name, verbose=False)\n",
        "\n",
        "teacher = teacher.to(device)\n",
        "teacher.eval()\n",
        "\n",
        "# Freeze all parameters\n",
        "for param in teacher.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_params = sum(p.numel() for p in teacher.parameters())\n",
        "print(f\"✓ Teacher loaded: {teacher_name}\")\n",
        "print(f\"  Parameters: {num_params / 1e6:.2f}M\")\n",
        "print(f\"  Frozen: True\")\n",
        "print(f\"  NOT compiled (frozen model, no benefit)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Student Model (ViT-S/16) - Will Be Compiled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Creating student model...\")\n",
        "student_name = model_cfg['student_name']\n",
        "student_img_size = model_cfg['student_img_size']\n",
        "\n",
        "student = timm.create_model(\n",
        "    student_name,\n",
        "    pretrained=False,  # Random initialization\n",
        "    img_size=student_img_size,\n",
        "    num_classes=0,  # No classification head\n",
        ")\n",
        "student = student.to(device)\n",
        "student.train()\n",
        "\n",
        "num_params = sum(p.numel() for p in student.parameters())\n",
        "trainable_params = sum(p.numel() for p in student.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"✓ Student created: {student_name}\")\n",
        "print(f\"  Parameters: {num_params / 1e6:.2f}M\")\n",
        "print(f\"  Trainable: {trainable_params / 1e6:.2f}M\")\n",
        "print(f\"  Image size: {student_img_size}x{student_img_size}\")\n",
        "\n",
        "# Compile student for speed (only if enabled)\n",
        "compile_student = train_cfg.get('compile_student', True)\n",
        "if compile_student and hasattr(torch, 'compile'):\n",
        "    print(\"\\nCompiling student model with torch.compile...\")\n",
        "    print(\"⚠️  First compilation may take 5-10 minutes - this is normal!\")\n",
        "    student = torch.compile(student, mode='reduce-overhead')\n",
        "    print(\"✓ Student model compiled successfully\")\n",
        "else:\n",
        "    print(\"✓ Student model NOT compiled (compile_student=False or PyTorch < 2.0)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Training Data (Cached or Original Mode)\n",
        "\n",
        "The `build_pretraining_dataloader` function automatically handles:\n",
        "- **Cached mode** (`use_cached: true`): Loads from tensor shards (fast)\n",
        "- **Original mode** (`use_cached: false`): Loads from HuggingFace (slower)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build DataLoader using factory function (handles cached vs original mode)\n",
        "print(\"Building DataLoader...\")\n",
        "dataloader = build_pretraining_dataloader(data_cfg, train_cfg)\n",
        "\n",
        "total_batches = len(dataloader)\n",
        "print(f\"\\n✓ DataLoader created: {total_batches} batches per epoch\")\n",
        "\n",
        "if max_steps_per_epoch:\n",
        "    print(f\"  With step cap: Each epoch will process {min(max_steps_per_epoch, total_batches)} batches\")\n",
        "    print(f\"  Estimated time per epoch: ~{min(max_steps_per_epoch, total_batches) * 0.5 / 60:.1f} minutes\")\n",
        "else:\n",
        "    print(f\"  Full epoch: All {total_batches} batches will be processed\")\n",
        "\n",
        "# Test data loading\n",
        "print(\"\\nTesting data loading...\")\n",
        "try:\n",
        "    test_batch = next(iter(dataloader))\n",
        "    if isinstance(test_batch, list):\n",
        "        print(f\"✓ Data loading works! Batch has {len(test_batch)} crops\")\n",
        "        print(f\"  First crop shape: {test_batch[0].shape}\")\n",
        "    else:\n",
        "        print(f\"✓ Data loading works! Batch shape: {test_batch.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  Data loading test failed: {e}\")\n",
        "    if use_cached:\n",
        "        print(\"   Make sure you've run Stage 1 (precompute cache) first!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Feature Extraction Functions (with Optional Caching)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_teacher_features(teacher, images, use_cls_token=True, \n",
        "                            cache_dir=None, cache_key=None):\n",
        "    \"\"\"Extract features from frozen teacher model with optional caching\"\"\"\n",
        "    # Check cache if enabled\n",
        "    if cache_dir is not None and cache_key is not None:\n",
        "        cache_path = Path(cache_dir) / f\"{cache_key}.pt\"\n",
        "        if cache_path.exists():\n",
        "            cached = torch.load(cache_path, map_location=images.device)\n",
        "            return cached['cls'], cached['patches']\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        features = teacher.forward_features(images)\n",
        "        \n",
        "        # Handle DINOv2 output format (dict or tensor)\n",
        "        if isinstance(features, dict):\n",
        "            if 'x_norm_clstoken' in features:\n",
        "                cls_embedding = features['x_norm_clstoken']\n",
        "            elif 'cls_token' in features:\n",
        "                cls_embedding = features['cls_token']\n",
        "            else:\n",
        "                cls_embedding = features.get('x', features.get('tokens', None))[:, 0]\n",
        "            \n",
        "            if 'x_norm_patchtokens' in features:\n",
        "                patch_embeddings = features['x_norm_patchtokens']\n",
        "            elif 'patch_tokens' in features:\n",
        "                patch_embeddings = features['patch_tokens']\n",
        "            else:\n",
        "                patch_embeddings = features.get('x', features.get('tokens', None))[:, 1:]\n",
        "        else:\n",
        "            # Tensor format [B, N+1, D]\n",
        "            if use_cls_token:\n",
        "                cls_embedding = features[:, 0]\n",
        "            else:\n",
        "                cls_embedding = features[:, 1:].mean(dim=1)\n",
        "            patch_embeddings = features[:, 1:]\n",
        "        \n",
        "        # Normalize\n",
        "        cls_embedding = F.normalize(cls_embedding, dim=-1, p=2)\n",
        "        patch_embeddings = F.normalize(patch_embeddings, dim=-1, p=2)\n",
        "    \n",
        "    # Save to cache if enabled\n",
        "    if cache_dir is not None and cache_key is not None:\n",
        "        cache_path = Path(cache_dir) / f\"{cache_key}.pt\"\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "        torch.save({'cls': cls_embedding, 'patches': patch_embeddings}, cache_path)\n",
        "    \n",
        "    return cls_embedding, patch_embeddings\n",
        "\n",
        "\n",
        "def extract_student_features(student, images, use_cls_token=True):\n",
        "    \"\"\"Extract features from student model\"\"\"\n",
        "    features = student.forward_features(images)\n",
        "    \n",
        "    if use_cls_token:\n",
        "        cls_embedding = features[:, 0]\n",
        "    else:\n",
        "        cls_embedding = features[:, 1:].mean(dim=1)\n",
        "    \n",
        "    patch_embeddings = features[:, 1:]\n",
        "    \n",
        "    # Normalize\n",
        "    cls_embedding = F.normalize(cls_embedding, dim=-1, p=2)\n",
        "    patch_embeddings = F.normalize(patch_embeddings, dim=-1, p=2)\n",
        "    \n",
        "    return cls_embedding, patch_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_distillation_loss(student_cls, student_patches, \n",
        "                             teacher_cls, teacher_patches,\n",
        "                             loss_weights=None):\n",
        "    \"\"\"Compute distillation loss between student and teacher embeddings\"\"\"\n",
        "    if loss_weights is None:\n",
        "        loss_weights = {'cls': 1.0, 'patch': 0.5}\n",
        "    \n",
        "    # CLS token loss\n",
        "    if student_cls.shape[-1] == teacher_cls.shape[-1]:\n",
        "        loss_cls = F.mse_loss(student_cls, teacher_cls)\n",
        "    else:\n",
        "        # Different dimensions: use squared norm loss\n",
        "        student_sq_norm = (student_cls ** 2).sum(dim=-1)\n",
        "        teacher_sq_norm = (teacher_cls ** 2).sum(dim=-1)\n",
        "        loss_cls = F.mse_loss(student_sq_norm, teacher_sq_norm)\n",
        "    \n",
        "    # Patch embeddings loss\n",
        "    B_s, N_s, D_s = student_patches.shape\n",
        "    B_t, N_t, D_t = teacher_patches.shape\n",
        "    \n",
        "    if N_s == N_t and D_s == D_t:\n",
        "        loss_patch = F.mse_loss(student_patches, teacher_patches)\n",
        "    elif D_s == D_t:\n",
        "        if N_s < N_t:\n",
        "            teacher_patches = teacher_patches[:, :N_s, :]\n",
        "        else:\n",
        "            student_patches = student_patches[:, :N_t, :]\n",
        "        loss_patch = F.mse_loss(student_patches, teacher_patches)\n",
        "    else:\n",
        "        student_pooled = student_patches.mean(dim=1)\n",
        "        teacher_pooled = teacher_patches.mean(dim=1)\n",
        "        if D_s == D_t:\n",
        "            loss_patch = F.mse_loss(student_pooled, teacher_pooled)\n",
        "        else:\n",
        "            student_sq_norm = (student_pooled ** 2).sum(dim=-1)\n",
        "            teacher_sq_norm = (teacher_pooled ** 2).sum(dim=-1)\n",
        "            loss_patch = F.mse_loss(student_sq_norm, teacher_sq_norm)\n",
        "    \n",
        "    # Weighted combination\n",
        "    total_loss = loss_weights['cls'] * loss_cls + loss_weights['patch'] * loss_patch\n",
        "    \n",
        "    return total_loss, {\n",
        "        'total': total_loss.item(),\n",
        "        'cls': loss_cls.item(),\n",
        "        'patch': loss_patch.item()\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Setup Optimizer and Scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build optimizer\n",
        "optimizer = build_optimizer(\n",
        "    student,\n",
        "    lr=train_cfg['learning_rate'],\n",
        "    weight_decay=train_cfg['weight_decay'],\n",
        "    fused=train_cfg.get('use_fused_adamw', True)\n",
        ")\n",
        "\n",
        "# Build scheduler\n",
        "scheduler = build_scheduler(\n",
        "    optimizer,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    warmup_epochs=train_cfg['warmup_epochs']\n",
        ")\n",
        "\n",
        "# GradScaler for mixed precision\n",
        "scaler = GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "print(f\"✓ Optimizer: AdamW (lr={train_cfg['learning_rate']})\")\n",
        "print(f\"  Fused: {train_cfg.get('use_fused_adamw', True)}\")\n",
        "print(f\"✓ Scheduler: Cosine with {train_cfg['warmup_epochs']} warmup epochs\")\n",
        "print(f\"✓ Mixed precision: {'Enabled' if device.type == 'cuda' else 'Disabled'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Loop with Auto-Resume\n",
        "\n",
        "This training loop includes:\n",
        "- Step-capped epochs (max_steps_per_epoch)\n",
        "- Auto-resume from latest checkpoint\n",
        "- Teacher feature caching (optional)\n",
        "- Detailed timing (GPU/data/batch)\n",
        "- Step-based checkpointing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "num_epochs = train_cfg['num_epochs']\n",
        "loss_weights = train_cfg.get('distill_loss_weights', {'cls': 1.0, 'patch': 0.5})\n",
        "use_cls_token = model_cfg.get('use_cls_token', True)\n",
        "use_multi_crop = train_cfg.get('use_multi_crop', False)\n",
        "save_every = train_cfg.get('save_every', 0)  # 0 = only at end of epoch\n",
        "cache_teacher_features = train_cfg.get('cache_teacher_features', False)\n",
        "teacher_feature_dir = train_cfg.get('teacher_feature_dir', None)\n",
        "if teacher_feature_dir:\n",
        "    teacher_feature_dir = os.path.expandvars(teacher_feature_dir)\n",
        "\n",
        "# Determine max steps per epoch\n",
        "total_batches = len(dataloader)\n",
        "if max_steps_per_epoch is not None:\n",
        "    if max_steps_per_epoch > total_batches:\n",
        "        print(f\"⚠️  Warning: max_steps_per_epoch ({max_steps_per_epoch}) > total batches ({total_batches})\")\n",
        "        print(f\"   Falling back to full dataset pass\")\n",
        "        max_steps = total_batches\n",
        "    else:\n",
        "        max_steps = max_steps_per_epoch\n",
        "else:\n",
        "    max_steps = total_batches\n",
        "\n",
        "# Checkpoint directory\n",
        "checkpoint_dir = train_cfg.get('checkpoint_dir', './checkpoints')\n",
        "checkpoint_dir = os.path.expandvars(checkpoint_dir)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Auto-detect and load latest checkpoint if available\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    \"\"\"Find the latest checkpoint in the directory\"\"\"\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        return None\n",
        "    \n",
        "    # Look for checkpoint_latest.pth first\n",
        "    latest_path = os.path.join(checkpoint_dir, 'checkpoint_latest.pth')\n",
        "    if os.path.exists(latest_path):\n",
        "        return latest_path\n",
        "    \n",
        "    # Otherwise, find the highest epoch checkpoint\n",
        "    checkpoint_files = []\n",
        "    for f in os.listdir(checkpoint_dir):\n",
        "        if f.startswith('checkpoint_epoch_') and f.endswith('.pth'):\n",
        "            try:\n",
        "                epoch_num = int(f.replace('checkpoint_epoch_', '').replace('.pth', ''))\n",
        "                checkpoint_files.append((epoch_num, os.path.join(checkpoint_dir, f)))\n",
        "            except ValueError:\n",
        "                continue\n",
        "    \n",
        "    if checkpoint_files:\n",
        "        checkpoint_files.sort(key=lambda x: x[0], reverse=True)\n",
        "        return checkpoint_files[0][1]\n",
        "    \n",
        "    return None\n",
        "\n",
        "# Try to resume from latest checkpoint\n",
        "latest_checkpoint = find_latest_checkpoint(checkpoint_dir)\n",
        "start_epoch = 0\n",
        "global_step = 0\n",
        "\n",
        "if latest_checkpoint:\n",
        "    print(f\"\\n✓ Found checkpoint: {latest_checkpoint}\")\n",
        "    print(f\"  Loading checkpoint to resume training...\")\n",
        "    checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
        "    \n",
        "    student.load_state_dict(checkpoint['student'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    scaler.load_state_dict(checkpoint['scaler'])\n",
        "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "    global_step = checkpoint.get('global_step', 0)\n",
        "    \n",
        "    print(f\"✓ Resumed from epoch {start_epoch}, step {global_step}\")\n",
        "    if max_steps_per_epoch is not None:\n",
        "        print(f\"  Continuing with step cap: {max_steps_per_epoch} steps/epoch\")\n",
        "    \n",
        "    # Load previous losses if available (for visualization)\n",
        "    if 'train_losses' in checkpoint:\n",
        "        train_losses = checkpoint['train_losses']\n",
        "        cls_losses = checkpoint.get('cls_losses', [])\n",
        "        patch_losses = checkpoint.get('patch_losses', [])\n",
        "        print(f\"  Loaded previous training history: {len(train_losses)} epochs\")\n",
        "    else:\n",
        "        train_losses = []\n",
        "        cls_losses = []\n",
        "        patch_losses = []\n",
        "else:\n",
        "    print(f\"\\n✓ No checkpoint found, starting from scratch\")\n",
        "    train_losses = []\n",
        "    cls_losses = []\n",
        "    patch_losses = []\n",
        "\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "print(f\"  Starting from epoch: {start_epoch + 1}\")\n",
        "print(f\"Loss weights: CLS={loss_weights['cls']}, Patch={loss_weights['patch']}\")\n",
        "if max_steps < total_batches:\n",
        "    print(f\"Step-capped: {max_steps} steps per epoch (out of {total_batches} total)\")\n",
        "    print(f\"Estimated time per epoch: ~{max_steps * 0.5 / 60:.1f} minutes\")\n",
        "else:\n",
        "    print(f\"Full epoch: {total_batches} steps per epoch\")\n",
        "if save_every > 0:\n",
        "    print(f\"Checkpointing: Every {save_every} steps\")\n",
        "else:\n",
        "    print(f\"Checkpointing: Only at end of each epoch\")\n",
        "if use_cached:\n",
        "    print(f\"Data mode: Cached tensors (fast loading)\")\n",
        "else:\n",
        "    print(f\"Data mode: Original (HuggingFace)\")\n",
        "print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop with all optimizations\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    student.train()\n",
        "    epoch_losses = {'total': [], 'cls': [], 'patch': []}\n",
        "    \n",
        "    # Use itertools.islice to limit iterations (avoids KeyError with DataLoader)\n",
        "    limited_dataloader = itertools.islice(dataloader, max_steps)\n",
        "    \n",
        "    desc = f\"Epoch {epoch+1}/{num_epochs}\"\n",
        "    if max_steps < total_batches:\n",
        "        desc += f\" (capped at {max_steps}/{total_batches} steps)\"\n",
        "    \n",
        "    progress_bar = tqdm(limited_dataloader, desc=desc, total=max_steps)\n",
        "    \n",
        "    batch_times = []\n",
        "    data_times = []\n",
        "    gpu_times = []\n",
        "    prev_iter_time = time.time()\n",
        "    steps_completed = 0\n",
        "    \n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        iter_start = time.time()\n",
        "        data_load_time = iter_start - prev_iter_time if batch_idx > 0 else 0\n",
        "        \n",
        "        batch_start = time.time()\n",
        "        \n",
        "        # Handle multi-crop or single image\n",
        "        if use_multi_crop and isinstance(batch, list):\n",
        "            images = batch[0].to(device)  # Use first global crop\n",
        "        else:\n",
        "            images = batch.to(device)\n",
        "        \n",
        "        # Convert to channels_last if supported\n",
        "        try:\n",
        "            images = images.to(memory_format=torch.channels_last)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        gpu_start = time.time()\n",
        "        \n",
        "        # Mixed precision training\n",
        "        if device.type == 'cuda':\n",
        "            if AUTOCAST_NEW_API:\n",
        "                with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "                    # Teacher forward with optional caching\n",
        "                    cache_key = None\n",
        "                    if cache_teacher_features:\n",
        "                        cache_key = hashlib.md5(images.cpu().numpy().tobytes()).hexdigest()\n",
        "                    \n",
        "                    teacher_cls, teacher_patches = extract_teacher_features(\n",
        "                        teacher, images, use_cls_token=use_cls_token,\n",
        "                        cache_dir=teacher_feature_dir, cache_key=cache_key\n",
        "                    )\n",
        "                    \n",
        "                    # Student forward\n",
        "                    student_cls, student_patches = extract_student_features(\n",
        "                        student, images, use_cls_token=use_cls_token\n",
        "                    )\n",
        "                    \n",
        "                    # Compute distillation loss\n",
        "                    loss, metrics = compute_distillation_loss(\n",
        "                        student_cls, student_patches,\n",
        "                        teacher_cls, teacher_patches,\n",
        "                        loss_weights=loss_weights\n",
        "                    )\n",
        "            else:\n",
        "                with autocast():\n",
        "                    cache_key = None\n",
        "                    if cache_teacher_features:\n",
        "                        cache_key = hashlib.md5(images.cpu().numpy().tobytes()).hexdigest()\n",
        "                    \n",
        "                    teacher_cls, teacher_patches = extract_teacher_features(\n",
        "                        teacher, images, use_cls_token=use_cls_token,\n",
        "                        cache_dir=teacher_feature_dir, cache_key=cache_key\n",
        "                    )\n",
        "                    \n",
        "                    student_cls, student_patches = extract_student_features(\n",
        "                        student, images, use_cls_token=use_cls_token\n",
        "                    )\n",
        "                    \n",
        "                    loss, metrics = compute_distillation_loss(\n",
        "                        student_cls, student_patches,\n",
        "                        teacher_cls, teacher_patches,\n",
        "                        loss_weights=loss_weights\n",
        "                    )\n",
        "        else:\n",
        "            # CPU: no autocast\n",
        "            cache_key = None\n",
        "            if cache_teacher_features:\n",
        "                cache_key = hashlib.md5(images.cpu().numpy().tobytes()).hexdigest()\n",
        "            \n",
        "            teacher_cls, teacher_patches = extract_teacher_features(\n",
        "                teacher, images, use_cls_token=use_cls_token,\n",
        "                cache_dir=teacher_feature_dir, cache_key=cache_key\n",
        "            )\n",
        "            \n",
        "            student_cls, student_patches = extract_student_features(\n",
        "                student, images, use_cls_token=use_cls_token\n",
        "            )\n",
        "            \n",
        "            loss, metrics = compute_distillation_loss(\n",
        "                student_cls, student_patches,\n",
        "                teacher_cls, teacher_patches,\n",
        "                loss_weights=loss_weights\n",
        "            )\n",
        "        \n",
        "        gpu_time = time.time() - gpu_start\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        # Track losses\n",
        "        epoch_losses['total'].append(metrics['total'])\n",
        "        epoch_losses['cls'].append(metrics['cls'])\n",
        "        epoch_losses['patch'].append(metrics['patch'])\n",
        "        steps_completed += 1\n",
        "        global_step += 1\n",
        "        \n",
        "        # Track times\n",
        "        batch_time = time.time() - batch_start\n",
        "        batch_times.append(batch_time)\n",
        "        data_times.append(data_load_time)\n",
        "        gpu_times.append(gpu_time)\n",
        "        if len(batch_times) > 10:\n",
        "            batch_times.pop(0)\n",
        "            data_times.pop(0)\n",
        "            gpu_times.pop(0)\n",
        "        \n",
        "        avg_batch_time = sum(batch_times) / len(batch_times)\n",
        "        avg_data_time = sum(data_times) / len(data_times) if data_times else 0\n",
        "        avg_gpu_time = sum(gpu_times) / len(gpu_times)\n",
        "        \n",
        "        # Update progress bar with detailed timing\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'cls': f'{metrics[\"cls\"]:.4f}',\n",
        "            'patch': f'{metrics[\"patch\"]:.4f}',\n",
        "            'lr': f'{current_lr:.6f}',\n",
        "            'gpu': f'{avg_gpu_time:.2f}s',\n",
        "            'data': f'{avg_data_time:.2f}s',\n",
        "            'batch': f'{avg_batch_time:.2f}s',\n",
        "            'step': f'{steps_completed}/{max_steps}'\n",
        "        })\n",
        "        \n",
        "        # Step-based checkpointing\n",
        "        if save_every > 0 and global_step % save_every == 0:\n",
        "            checkpoint = {\n",
        "                'student': student.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'scaler': scaler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'global_step': global_step,\n",
        "            }\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_step_{global_step}.pth\")\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_latest.pth\")\n",
        "            print(f\"\\n  ✓ Saved checkpoint at step {global_step}\")\n",
        "        \n",
        "        prev_iter_time = time.time()\n",
        "    \n",
        "    # Step scheduler at end of epoch\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Compute epoch averages\n",
        "    avg_loss = np.mean(epoch_losses['total'])\n",
        "    avg_cls = np.mean(epoch_losses['cls'])\n",
        "    avg_patch = np.mean(epoch_losses['patch'])\n",
        "    \n",
        "    train_losses.append(avg_loss)\n",
        "    cls_losses.append(avg_cls)\n",
        "    patch_losses.append(avg_patch)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} \"\n",
        "          f\"(CLS: {avg_cls:.4f}, Patch: {avg_patch:.4f}) \"\n",
        "          f\"[{steps_completed}/{max_steps} steps]\")\n",
        "    \n",
        "    # Save checkpoint at end of epoch\n",
        "    checkpoint = {\n",
        "        'student': student.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'scaler': scaler.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'global_step': global_step,\n",
        "        'train_losses': train_losses,  # Save training history\n",
        "        'cls_losses': cls_losses,\n",
        "        'patch_losses': patch_losses,\n",
        "    }\n",
        "    torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_latest.pth\")\n",
        "    torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\")\n",
        "    print(f\"  ✓ Saved checkpoint: checkpoint_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Total Loss')\n",
        "plt.plot(cls_losses, label='CLS Loss', alpha=0.7)\n",
        "plt.plot(patch_losses, label='Patch Loss', alpha=0.7)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Total Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Total Loss (Log Scale)')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Best loss: {min(train_losses):.4f} (epoch {np.argmin(train_losses)+1})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
